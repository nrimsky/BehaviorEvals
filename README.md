# Scripts for evaluating LLMs

## `ab_eval.py`

Evaluates whether partiuclar free text answers to questions are closer to a given option A or option B.

## `score_eval.py`

Generates a score for a particular free text answer to a question, given some criteria defined by a behavior name and example scores.